schema: '2.0'
stages:
  tokenize:
    cmd: uv sync && ./tokenizer/build/tokenize
    deps:
    - path: tokenizer/CMakeLists.txt
      hash: md5
      md5: f423c9f26c603962959c3724015d286e
      size: 4922
    - path: tokenizer/src/lib/dataloader.cpp
      hash: md5
      md5: 53ebf2ee5ada158ea331af08bcf08c69
      size: 2070
    - path: tokenizer/src/lib/dataloader.hpp
      hash: md5
      md5: 8c74b03b4a1f4f941751083457b5f6ca
      size: 600
    - path: tokenizer/src/lib/io.cpp
      hash: md5
      md5: 29106b39a48a20faa8d1973ede05ff93
      size: 6004
    - path: tokenizer/src/lib/io.hpp
      hash: md5
      md5: a8177ebb8c302e566c180770cdc09639
      size: 965
    - path: tokenizer/src/lib/text.cpp
      hash: md5
      md5: 419b587d7e870e7665231a8376ea9481
      size: 2872
    - path: tokenizer/src/lib/text.hpp
      hash: md5
      md5: d3d105e19ac1861ea43655dcf6cbfd6e
      size: 134
    - path: tokenizer/src/lib/threading.cpp
      hash: md5
      md5: 5497a70216e75242a6b969862c92fc3b
      size: 1367
    - path: tokenizer/src/lib/threading.hpp
      hash: md5
      md5: 36ad00dece0ca60fdd9f73d4d3d2e982
      size: 1134
    - path: tokenizer/src/lib/tokenizer.cpp
      hash: md5
      md5: 54cd9e6213efb6b49b65bd6b4fada1ce
      size: 42046
    - path: tokenizer/src/lib/tokenizer.hpp
      hash: md5
      md5: b66a3b6b1dd621a607e8837489f30465
      size: 2950
    - path: tokenizer/src/tokenize.cpp
      hash: md5
      md5: 33295b6d287a03f9ab2f10846a86cf61
      size: 5185
    params:
      params.yaml:
        data:
          train_file: out/tokenize/train.bin
          val_file: out/tokenize/val.bin
          tok_file: out/tokenize/tok.bin
          train_paths_file: out/tokenize/train_paths.txt
          val_paths_file: out/tokenize/val_paths.txt
          dataset_path: data/py150/data
          glob_pattern: '*.py'
          split_ratio: 0.7
          seed: 42
          max_unique_words: 0
          vocab_size: 20259
          pattern: ' ?[A-Za-z_(][A-Za-z_.]*|%(?:\.\d+)?[sdifFeEgGxXoc%]|[0-9]{1,3}|
            ?[^ %_A-Za-z0-9]+(?: ")?[\r\n]*|%|\s+$|\s+(?=\s)|\s'
          bos_token: ''
          eos_token: <|endoftext|>
          pad_token: <|pad|>
          seq_length: 256
          num_workers: 2
          eos_token_id: 20256
    outs:
    - path: out/tokenize
      hash: md5
      md5: c431b167c25ce6941660151a743c7d1b.dir
      size: 871552397
      nfiles: 5
  train:
    cmd: uv run python src/train.py
    deps:
    - path: out/tokenize
      hash: md5
      md5: c431b167c25ce6941660151a743c7d1b.dir
      size: 871552397
      nfiles: 5
    - path: src/dataloaders/py150.py
      hash: md5
      md5: ab28155ed04012c0a26b264834d78627
      size: 2995
    - path: src/dataloaders/py150_dataloader.py
      hash: md5
      md5: 84bddfce3179707dba648cffe49485cf
      size: 4571
    - path: src/models/qwen3.py
      hash: md5
      md5: 473e8503ac126c5263b8d5161a99db6d
      size: 8362
    - path: src/train.py
      hash: md5
      md5: 76f63feff41790e4e809984a20d13eba
      size: 10180
    params:
      params.yaml:
        data:
          train_file: out/tokenize/train.bin
          val_file: out/tokenize/val.bin
          tok_file: out/tokenize/tok.bin
          train_paths_file: out/tokenize/train_paths.txt
          val_paths_file: out/tokenize/val_paths.txt
          dataset_path: data/py150/data
          glob_pattern: '*.py'
          split_ratio: 0.7
          seed: 42
          max_unique_words: 0
          vocab_size: 20259
          pattern: ' ?[A-Za-z_(][A-Za-z_.]*|%(?:\.\d+)?[sdifFeEgGxXoc%]|[0-9]{1,3}|
            ?[^ %_A-Za-z0-9]+(?: ")?[\r\n]*|%|\s+$|\s+(?=\s)|\s'
          bos_token: ''
          eos_token: <|endoftext|>
          pad_token: <|pad|>
          seq_length: 256
          num_workers: 2
          eos_token_id: 20256
        model:
          hidden_size: 512
          num_hidden_layers: 4
          num_attention_heads: 16
          num_key_value_heads: 8
          intermediate_size: 1024
          max_position_embeddings: 2048
          rope_theta: 10000.0
          attention_dropout: 0.1
          rms_norm_eps: 1e-06
          use_sliding_window: false
          sliding_window: 4096
        other:
          save_dir: out/train/checkpoints
          log_dir: out/train/logs
        training:
          prefix: qwen3
          batch_size: 32
          epochs: 50
          lr: 0.0001
          weight_decay: 0.01
          grad_clip: 1.0
          gradient_accumulation_steps: 4
          max_batches_per_epoch: 750
          use_amp: false
          compile_mode: max-autotune
          seed: 42
          warmup_steps: 5
          scheduler_t_max: 50
    outs:
    - path: out/train/checkpoints/best.ckpt
      hash: md5
      md5: f2a1317a4c1f6d838743a6c56b39c736
      size: 475563463
    - path: out/train/checkpoints/latest.ckpt
      hash: md5
      md5: f2a1317a4c1f6d838743a6c56b39c736
      size: 475563463
    - path: out/train/checkpoints/metrics.json
      hash: md5
      md5: 5c2655bd0a5dc90f03e17c6670f92522
      size: 101
    - path: out/train/logs
      hash: md5
      md5: 1b847d75762da59b418d56e095298e82.dir
      size: 28370
      nfiles: 10
