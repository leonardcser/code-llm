schema: '2.0'
stages:
  tokenize:
    cmd: mkdir -p tokenizer/build && cmake -S tokenizer -B tokenizer/build 
      -DCMAKE_BUILD_TYPE=Release && cmake --build tokenizer/build -j$(nproc) && 
      ./tokenizer/build/tokenize
    deps:
    - path: tokenizer/CMakeLists.txt
      hash: md5
      md5: a4405d1f0a2e1dd5f723ca8e96c2a227
      size: 5323
    - path: tokenizer/src/lib/dataloader.cpp
      hash: md5
      md5: 53ebf2ee5ada158ea331af08bcf08c69
      size: 2070
    - path: tokenizer/src/lib/dataloader.hpp
      hash: md5
      md5: 8c74b03b4a1f4f941751083457b5f6ca
      size: 600
    - path: tokenizer/src/lib/io.cpp
      hash: md5
      md5: 29106b39a48a20faa8d1973ede05ff93
      size: 6004
    - path: tokenizer/src/lib/io.hpp
      hash: md5
      md5: a8177ebb8c302e566c180770cdc09639
      size: 965
    - path: tokenizer/src/lib/text.cpp
      hash: md5
      md5: 419b587d7e870e7665231a8376ea9481
      size: 2872
    - path: tokenizer/src/lib/text.hpp
      hash: md5
      md5: d3d105e19ac1861ea43655dcf6cbfd6e
      size: 134
    - path: tokenizer/src/lib/threading.cpp
      hash: md5
      md5: 5497a70216e75242a6b969862c92fc3b
      size: 1367
    - path: tokenizer/src/lib/threading.hpp
      hash: md5
      md5: 36ad00dece0ca60fdd9f73d4d3d2e982
      size: 1134
    - path: tokenizer/src/lib/tokenizer.cpp
      hash: md5
      md5: cd155bc8db382f7b3dc9b7c6eab09d1d
      size: 42063
    - path: tokenizer/src/lib/tokenizer.hpp
      hash: md5
      md5: b7bea226ec8c03212c41cd4bc974d5c6
      size: 2969
    - path: tokenizer/src/tokenize.cpp
      hash: md5
      md5: 5316998dd659988726bdc1d9bb680b93
      size: 3925
    params:
      params.yaml:
        data.bos_token: <|startoftext|>
        data.dataset_file: out/tokenize/dataset.bin
        data.dataset_path: data/py150/data
        data.eos_token: <|endoftext|>
        data.glob_pattern: '*.py'
        data.max_unique_words: 0
        data.pad_token: <|pad|>
        data.pattern: "'(?i:[sdmt]|ll|ve|re)| ?[A-Za-z_(][A-Za-z_.]*|%(?:\\.\\d+)?[sdifFeEgGxXoc%]|[0-9]{1,3}|
          ?[^ %_A-Za-z0-9]+(?: \")?[\\r\\n]*|%|\\s+$|\\s+(?=\\s)|\\s"
        data.seed: 42
        data.split_ratio: 0.7
        data.tok_file: out/tokenize/tok.bin
        data.vocab_size: 20260
    outs:
    - path: out/tokenize
      hash: md5
      md5: 4e90246a8c7f70c0d9a2a4d5d86835a5.dir
      size: 859062588
      nfiles: 2
  train:
    cmd: uv run python src/train.py
    deps:
    - path: out/tokenize
      hash: md5
      md5: 4e90246a8c7f70c0d9a2a4d5d86835a5.dir
      size: 859062588
      nfiles: 2
    - path: src/dataloaders/py150.py
      hash: md5
      md5: 8a6707980e3c9cd762787a93b23b21d6
      size: 7367
    - path: src/dataloaders/py150_dataloader.py
      hash: md5
      md5: 4cc60f04ffe920577911675367972a52
      size: 8909
    - path: src/models/qwen3.py
      hash: md5
      md5: c4dc31b999219996d36ffa499df92acc
      size: 10286
    - path: src/train.py
      hash: md5
      md5: 84cea5f85c9784f03f6a9af3c7bf59b7
      size: 8728
    - path: src/trainers/trainer.py
      hash: md5
      md5: df2c34be5155c9f8b20d212b784d5f26
      size: 15905
    params:
      params.yaml:
        data.bos_token_id: 20256
        data.eos_token_id: 20257
        data.max_tokens: 10000000
        data.num_workers: 6
        data.pad_token_id: 20258
        data.seq_length: 256
        model:
          hidden_size: 512
          num_hidden_layers: 4
          num_attention_heads: 16
          num_key_value_heads: 8
          intermediate_size: 1024
          max_position_embeddings: 2048
          rope_theta: 10000.0
          attention_dropout: 0.1
          rms_norm_eps: 1e-06
          use_sliding_window: false
          sliding_window: 4096
        training:
          prefix: qwen3
          batch_size: 32
          epochs: 50
          lr: 0.0001
          weight_decay: 0.01
          grad_clip: 1.0
          gradient_accumulation_steps: 4
          use_amp: true
          compile_mode: max-autotune
          devices: 1
          strategy: auto
          seed: 42
          warmup_steps: 3750
          scheduler_t_max_steps:
          log_every_n_steps: 50
          save_dir: out/train/checkpoints
          log_dir: out/train/logs
    outs:
    - path: out/train/checkpoints/best.ckpt
      hash: md5
      md5: a92dc1c4d9456fc7d9116b06fe8c2435
      size: 475574599
    - path: out/train/checkpoints/latest.ckpt
      hash: md5
      md5: 694152e9a9ee61ab5975c66fd40eed5e
      size: 475574599
    - path: out/train/checkpoints/metrics.json
      hash: md5
      md5: 4301e4809f7c28d7dd8bb8d294e976d0
      size: 101
    - path: out/train/logs
      hash: md5
      md5: 036d8b57209a6a34e1f1dd75924c100b.dir
      size: 52375
      nfiles: 1
