stages:
  tokenize:
    cmd: mkdir -p tokenizer/build && cmake -S tokenizer -B tokenizer/build -DCMAKE_BUILD_TYPE=Release && cmake --build tokenizer/build -j$(nproc) && ./tokenizer/build/tokenize
    deps:
      - tokenizer/CMakeLists.txt
      - tokenizer/src/lib/dataloader.cpp
      - tokenizer/src/lib/dataloader.hpp
      - tokenizer/src/lib/io.cpp
      - tokenizer/src/lib/io.hpp
      - tokenizer/src/lib/text.cpp
      - tokenizer/src/lib/text.hpp
      - tokenizer/src/lib/threading.cpp
      - tokenizer/src/lib/threading.hpp
      - tokenizer/src/lib/tokenizer.cpp
      - tokenizer/src/lib/tokenizer.hpp
      - tokenizer/src/tokenize.cpp
    params:
      - data.train_file
      - data.val_file
      - data.tok_file
      - data.train_paths_file
      - data.val_paths_file
      - data.dataset_path
      - data.glob_pattern
      - data.split_ratio
      - data.seed
      - data.max_unique_words
      - data.vocab_size
      - data.pattern
      - data.bos_token
      - data.eos_token
      - data.pad_token
      - data.bos_token_id
      - data.eos_token_id
    outs:
      - out/tokenize

  train:
    cmd: uv run python src/train.py
    deps:
      - out/tokenize
      - src/train.py
      - src/models/qwen3.py
      - src/dataloaders/py150.py
      - src/dataloaders/py150_dataloader.py
    params:
      - data
      - model
      - training
      - other
    outs:
      - out/train/checkpoints/best.ckpt
      - out/train/checkpoints/latest.ckpt
      - out/train/logs:
          persist: true
    metrics:
      - out/train/checkpoints/metrics.json:
          cache: false
